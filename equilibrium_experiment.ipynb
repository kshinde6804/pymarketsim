{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ZI Agent Equilibrium Experiment\n\nFind Nash equilibrium strategies among ZI agents by testing all 10\u00d710 combinations of background vs. deviator strategy pairs.\n\n**Setup:**\n- **16 agents total:** 15 background agents (all playing the same strategy) + 1 deviator\n- **10 strategies** parameterized by `shade` (pricing offset range) and `eta` (order improvement aggressiveness)\n- **100 runs \u00d7 1,000 time steps** per (background, deviator) strategy pair \u2192 100,000 total simulations\n- **Output:** 10\u00d710 advantage matrix where cell [BG=i, Dev=j] = mean(deviator profit) \u2212 mean(background profit)\n\nA strategy **S\\*** is a **Nash equilibrium candidate** if the deviator's best response when all 15 background agents play S\\* is S\\* itself \u2014 i.e., no profitable deviation exists.",
   "id": "1857162f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Imports",
   "id": "cdf28ff0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ensure jinja2 is available for pandas Styler\ntry:\n    import jinja2\nexcept ImportError:\n    import subprocess, sys\n    subprocess.run([sys.executable, '-m', 'pip', 'install', 'jinja2'], check=True)\n\nimport numpy as np\nimport pandas as pd\nimport multiprocessing as mp\nimport platform\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm.auto import tqdm\nfrom IPython.display import display\n\nfrom marketsim.simulator.simulator import Simulator\nfrom marketsim.agent.zero_intelligence_agent import ZIAgent",
   "id": "c17c9b4f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Strategy Definitions\n\nEach strategy is a `(shade, eta)` pair:\n- **`shade = [lo, hi]`** \u2014 the agent draws a uniform offset from `[lo, hi]` and places its limit order that far from its fair-value estimate. Wider shade \u2192 more conservative (demands more margin).\n- **`eta`** \u2014 order improvement parameter. If `eta < 1`, the agent will match the best counterparty quote when it is within `eta \u00d7 offset` of the agent's fair value. `eta = 1.0` means no improvement (strict limit orders).",
   "id": "42431f1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "STRATEGIES = {\n    0: {'shade': [0,   450],  'eta': 0.5},\n    1: {'shade': [0,   600],  'eta': 0.5},\n    2: {'shade': [90,  110],  'eta': 0.5},\n    3: {'shade': [140, 160],  'eta': 0.5},\n    4: {'shade': [190, 210],  'eta': 0.5},\n    5: {'shade': [280, 320],  'eta': 0.5},\n    6: {'shade': [380, 420],  'eta': 0.5},\n    7: {'shade': [380, 420],  'eta': 1.0},\n    8: {'shade': [460, 540],  'eta': 0.5},\n    9: {'shade': [950, 1050], 'eta': 0.5},\n}\n\n# Human-readable labels used in summary tables\nDESC = {\n    0: 'shade=[0,450]   \u03b7=0.5',\n    1: 'shade=[0,600]   \u03b7=0.5',\n    2: 'shade=[90,110]  \u03b7=0.5',\n    3: 'shade=[140,160] \u03b7=0.5',\n    4: 'shade=[190,210] \u03b7=0.5',\n    5: 'shade=[280,320] \u03b7=0.5',\n    6: 'shade=[380,420] \u03b7=0.5',\n    7: 'shade=[380,420] \u03b7=1.0',\n    8: 'shade=[460,540] \u03b7=0.5',\n    9: 'shade=[950,1050] \u03b7=0.5',\n}\n\nN_STRATEGIES = len(STRATEGIES)\nprint(f\"{N_STRATEGIES} strategies defined:\")\nfor k, v in STRATEGIES.items():\n    print(f\"  S{k}: shade={v['shade']}  eta={v['eta']}\")",
   "id": "aa2849c1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Market Environment Parameters\n\nEnvironment B from the paper. Modify these to test different market conditions.",
   "id": "d6a7c0f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ENV = {\n    'lam':       0.005,   # arrival intensity \u2014 prob. each agent acts per time step\n    'mean':      1e5,     # long-run fundamental value\n    'r':         0.01,    # mean-reversion speed (kappa)\n    'shock_var': 1e6,     # variance of fundamental shocks\n    'pv_var':    5e6,     # private value variance\n    'q_max':     10,      # maximum agent position\n    'sim_time':  1000,    # time steps per simulation run\n    'n_bg':      15,      # number of background agents\n}\n\nNUM_RUNS = 100  # repetitions per (bg, dev) cell\n\ntotal_sims = N_STRATEGIES ** 2 * NUM_RUNS\nprint(f\"Environment : lam={ENV['lam']}, mean={ENV['mean']:.0f}, r={ENV['r']}\")\nprint(f\"Agents      : 1 deviator + {ENV['n_bg']} background = {ENV['n_bg']+1} total\")\nprint(f\"Simulations : {N_STRATEGIES}x{N_STRATEGIES} cells \u00d7 {NUM_RUNS} runs = {total_sims:,} total\")",
   "id": "c65d2f78"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Simulation Functions\n\n`_build_and_run_sim` runs a single simulation and returns the deviator profit and mean background profit.\n\n`_run_cell` repeats this `num_runs` times for one (bg, dev) cell and returns the means.\n\n> **Note on multiprocessing:** on macOS, this uses `fork`-based multiprocessing so the worker function can be defined here in the notebook. On other platforms it falls back to sequential execution.",
   "id": "2c4c52ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def _build_and_run_sim(bg_shade, bg_eta, dev_shade, dev_eta):\n    \"\"\"Build and run a single simulation. Returns (dev_profit, mean_bg_profit).\"\"\"\n    sim = Simulator(\n        num_background_agents=0,\n        sim_time=ENV['sim_time'],\n        num_assets=1,\n        lam=ENV['lam'],\n        mean=ENV['mean'],\n        r=ENV['r'],\n        shock_var=ENV['shock_var'],\n        q_max=ENV['q_max'],\n        pv_var=ENV['pv_var'],\n    )\n    sim.agents = {}\n\n    # Agent 0: deviator\n    sim.agents[0] = ZIAgent(\n        agent_id=0, market=sim.markets[0],\n        q_max=ENV['q_max'], shade=dev_shade, eta=dev_eta, pv_var=ENV['pv_var'],\n    )\n    # Agents 1\u2013n_bg: background (all same strategy)\n    for i in range(1, ENV['n_bg'] + 1):\n        sim.agents[i] = ZIAgent(\n            agent_id=i, market=sim.markets[0],\n            q_max=ENV['q_max'], shade=bg_shade, eta=bg_eta, pv_var=ENV['pv_var'],\n        )\n\n    sim.run()\n    fv = sim.markets[0].get_final_fundamental()\n\n    def profit(agent):\n        return agent.get_pos_value() + agent.position * fv + agent.cash\n\n    dev_p = profit(sim.agents[0])\n    bg_p  = float(np.mean([profit(sim.agents[i]) for i in range(1, ENV['n_bg'] + 1)]))\n    return dev_p, bg_p\n\n\ndef _run_cell(args):\n    \"\"\"Worker: run num_runs simulations for one (bg_idx, dev_idx) cell.\"\"\"\n    bg_idx, dev_idx, num_runs = args\n    bg  = STRATEGIES[bg_idx]\n    dev = STRATEGIES[dev_idx]\n    dev_profits, bg_profits = [], []\n    for _ in range(num_runs):\n        d, b = _build_and_run_sim(bg['shade'], bg['eta'], dev['shade'], dev['eta'])\n        dev_profits.append(d)\n        bg_profits.append(b)\n    return bg_idx, dev_idx, float(np.mean(dev_profits)), float(np.mean(bg_profits))\n\n\nprint('Simulation functions defined.')",
   "id": "e7ebb812"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_equilibrium_experiment(num_runs=NUM_RUNS, n_processes=None):\n    \"\"\"\n    Sweep all N\u00d7N (background, deviator) strategy pairs.\n\n    Returns\n    -------\n    pd.DataFrame of shape (N_STRATEGIES, N_STRATEGIES)\n        df.loc['Si', 'Sj'] = mean(deviator profit) - mean(background profit)\n        when background plays strategy i and deviator plays strategy j.\n    \"\"\"\n    n = N_STRATEGIES\n    tasks = [(bg, dev, num_runs) for bg in range(n) for dev in range(n)]\n    advantage = np.zeros((n, n))\n\n    on_mac = platform.system() == 'Darwin'\n    if on_mac and n_processes != 1:\n        if n_processes is None:\n            n_processes = mp.cpu_count()\n        print(f\"Running on {n_processes} cores (fork) \u2014 {len(tasks) * num_runs:,} simulations...\")\n        ctx = mp.get_context('fork')\n        with ctx.Pool(n_processes) as pool:\n            for bg_idx, dev_idx, dev_mean, bg_mean in tqdm(\n                pool.imap_unordered(_run_cell, tasks),\n                total=len(tasks), desc='cells',\n            ):\n                advantage[bg_idx, dev_idx] = dev_mean - bg_mean\n    else:\n        print(f\"Running sequentially \u2014 {len(tasks) * num_runs:,} simulations...\")\n        for args in tqdm(tasks, desc='cells'):\n            bg_idx, dev_idx, dev_mean, bg_mean = _run_cell(args)\n            advantage[bg_idx, dev_idx] = dev_mean - bg_mean\n\n    labels = [f'S{i}' for i in range(n)]\n    return pd.DataFrame(\n        advantage,\n        index=pd.Index(labels, name='BG Strategy'),\n        columns=pd.Index(labels, name='Deviator'),\n    )\n\n\nprint('Experiment runner defined.')",
   "id": "109fdd70"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Run the Experiment\n\nThis is the slow cell. Run it once and use the display cells below to explore results without repeating the computation.",
   "id": "4b14cad4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = run_equilibrium_experiment()\nprint(f\"\\nComplete. Result shape: {df.shape}\")",
   "id": "7546d2f0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Results\n\n### 6a. Profit Advantage Matrix\n\nEach cell shows **mean(deviator profit) \u2212 mean(background profit)**.\n- **Green** \u2192 deviator earns more than the background agents\n- **Red** \u2192 deviator earns less\n- **Bold + underline** \u2192 best deviation strategy for that row (what a rational deviator would choose)\n\nRows are the background strategy; columns are the deviator's strategy.",
   "id": "7653cff9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def style_advantage_table(df):\n    max_val = df.abs().max().max()\n    caption = (\n        \"Profit Advantage Matrix \u2014 mean(deviator profit) \\u2212 mean(background profit)  |  \"\n        \"Green\\u2009=\\u2009deviator earns more  \\u00b7  Red\\u2009=\\u2009deviator earns less  \\u00b7  \"\n        \"Bold+underline\\u2009=\\u2009best deviation per row\"\n    )\n    return (\n        df.style\n        .background_gradient(cmap='RdYlGn', axis=None, vmin=-max_val, vmax=max_val)\n        .highlight_max(axis=1, props='font-weight: bold; text-decoration: underline')\n        .format('{:.0f}')\n        .set_caption(caption)\n        .set_table_styles([\n            {'selector': 'caption', 'props': [\n                ('font-size', '13px'), ('font-weight', 'bold'),\n                ('text-align', 'left'), ('margin-bottom', '10px'), ('color', '#333'),\n            ]},\n            {'selector': 'th', 'props': [\n                ('font-size', '11px'), ('text-align', 'center'),\n                ('padding', '5px 10px'), ('border', '1px solid #ccc'),\n                ('background-color', '#f5f5f5'),\n            ]},\n            {'selector': 'td', 'props': [\n                ('text-align', 'center'), ('padding', '5px 10px'),\n                ('font-size', '11px'), ('border', '1px solid #e0e0e0'),\n            ]},\n        ])\n    )\n\nstyle_advantage_table(df)",
   "id": "998a49fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6b. Best Deviation Summary\n\nFor each background strategy, which strategy does the deviator prefer? Rows highlighted in green are Nash equilibrium candidates.",
   "id": "36c19d09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def make_summary_table(df):\n    best_label = df.idxmax(axis=1)   # e.g. 'S3' \u2014 best deviator strategy per row\n    best_adv   = df.max(axis=1)      # profit advantage of that best deviation\n\n    rows = []\n    for bg_label in df.index:\n        bg_i  = int(bg_label[1:])\n        dev_label = best_label[bg_label]\n        dev_i = int(dev_label[1:])\n        adv   = best_adv[bg_label]\n        is_ne = (bg_label == dev_label)\n        rows.append({\n            'BG Strategy': bg_label,\n            'BG Params':   DESC[bg_i],\n            'Best Deviation': dev_label,\n            'Dev Params':  DESC[dev_i],\n            'Advantage':   round(adv, 1),\n            'Nash Eq?':    '\\u2713 NE' if is_ne else '',\n        })\n\n    summary = pd.DataFrame(rows).set_index('BG Strategy')\n\n    def highlight_ne(row):\n        style = 'background-color: #c8f5c8; font-weight: bold' if row['Nash Eq?'] else ''\n        return [style] * len(row)\n\n    return (\n        summary.style\n        .apply(highlight_ne, axis=1)\n        .format({'Advantage': '{:.1f}'})\n        .set_caption('Best Deviator Strategy per Background Strategy  (green = Nash equilibrium candidate)')\n        .set_table_styles([\n            {'selector': 'caption', 'props': [\n                ('font-size', '13px'), ('font-weight', 'bold'),\n                ('text-align', 'left'), ('margin-bottom', '10px'),\n            ]},\n            {'selector': 'th', 'props': [\n                ('font-size', '11px'), ('text-align', 'center'),\n                ('padding', '5px 12px'), ('border', '1px solid #ccc'),\n                ('background-color', '#f5f5f5'),\n            ]},\n            {'selector': 'td', 'props': [\n                ('font-size', '11px'), ('text-align', 'center'),\n                ('padding', '5px 12px'), ('border', '1px solid #e0e0e0'),\n            ]},\n        ])\n    )\n\nmake_summary_table(df)",
   "id": "e29c91d7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6c. Nash Equilibrium Analysis",
   "id": "9938bb66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_label = df.idxmax(axis=1)\nn\u0435_candidates = [label for label in df.index if best_label[label] == label]\n\nprint('=' * 60)\nprint('NASH EQUILIBRIUM ANALYSIS')\nprint('=' * 60)\n\nif n\u0435_candidates:\n    print(f'\\n{len(n\u0435_candidates)} Nash equilibrium candidate(s) found:\\n')\n    for label in n\u0435_candidates:\n        i = int(label[1:])\n        s = STRATEGIES[i]\n        adv = df.loc[label, label]\n        print(f'  {label}  shade={s[\"shade\"]}  eta={s[\"eta\"]}')\n        print(f'       Best deviation = {label} (same strategy, advantage = {adv:.1f})')\nelse:\n    print('\\nNo pure-strategy Nash equilibrium found among the 10 strategies.')\n    print('\\nStrategies ranked by how close they are to being equilibria')\n    print('(smallest gap between best-deviation advantage and own-strategy advantage):\\n')\n    best_adv  = df.max(axis=1)\n    diag_adv  = pd.Series({label: df.loc[label, label] for label in df.index})\n    gap = best_adv - diag_adv\n    gap_df = pd.DataFrame({\n        'Strategy':      gap.index,\n        'Params':        [DESC[int(l[1:])] for l in gap.index],\n        'Own Adv':       [round(diag_adv[l], 1) for l in gap.index],\n        'Best Dev Adv':  [round(best_adv[l], 1)  for l in gap.index],\n        'Gap':           [round(g, 1) for g in gap.values],\n    }).sort_values('Gap').reset_index(drop=True)\n    print(gap_df.to_string(index=False))\n\nprint('\\n' + '=' * 60)",
   "id": "6f4658a3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Save Results",
   "id": "890192f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "out_path = 'equilibrium_results.csv'\ndf.to_csv(out_path)\nprint(f'Advantage matrix saved to {out_path}')",
   "id": "249df877"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}